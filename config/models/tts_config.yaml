# TTS (Text-to-Speech) Configuration
# Change 'default' to switch between providers

default: "kokoro"  # Options: elevenlabs, openai, google, edge, kokoro

# =============================================================================
# RECOMMENDED OPEN-SOURCE TTS MODELS (2025-2026)
# =============================================================================
# Best Quality:
#   - Kokoro (82M params, #1 on HuggingFace TTS Arena, Apache 2.0)
#   - Dia 1.6B (Best for dialogue, supports non-verbal audio)
#   - OpenAudio S1 (Best multilingual, 2M+ hours training)
#
# Best for Voice Cloning:
#   - XTTS-v2 (6-second sample cloning, 20+ languages)
#   - OpenVoice (Good quality cloning)
#
# Best for Real-time:
#   - Kokoro (210x real-time on GPU, 3-11x on CPU)
#   - Piper (Very fast, good for edge devices)
#   - MeloTTS (Fast, good multilingual)
#
# Best Free Cloud:
#   - Edge TTS (Microsoft neural voices, free)
#   - Google TTS (gTTS, basic quality)
# =============================================================================

# Interview-specific TTS settings
interview_tts:
  enabled: true
  auto_speak_questions: true
  voice_profile: "professional_interviewer"
  speed: 0.95  # Slightly slower for clarity

providers:
  elevenlabs:
    api_key_env: "ELEVENLABS_API_KEY"
    voice_id: "21m00Tcm4TlvDq8ikWAM"  # Rachel - Professional female voice
    model_id: "eleven_multilingual_v2"
    stability: 0.5
    similarity_boost: 0.75
    # Available voices:
    # - 21m00Tcm4TlvDq8ikWAM (Rachel)
    # - EXAVITQu4vr4xnSDxMaL (Bella)
    # - ErXwobaYiN019PkySvjV (Antoni)
    # - MF3mGyEYCl7XYWbV9V6O (Elli)
    # - TxGEqnHWrfWFTfGW9XjX (Josh)

  openai:
    api_key_env: "OPENAI_API_KEY"
    model: "tts-1"
    voice: "nova"  # Options: alloy, echo, fable, onyx, nova, shimmer

  google:
    # Free option using gTTS library
    language: "en"
    tld: "com"  # Accent: com (US), co.uk (UK), com.au (AU), co.in (IN)
    slow: false

  edge:
    # Free Microsoft Edge TTS - High quality neural voices
    # Using more natural, conversational voices
    voice: "en-US-AndrewNeural"  # Natural male voice - warm and professional
    rate: "-3%"  # Slightly slower for natural conversation
    volume: "+0%"
    pitch: "-2Hz"  # Slightly deeper for warmth
    # Best voices for interview (most natural sounding):
    # MALE (Recommended for Alex):
    # - en-US-AndrewNeural (Warm, professional - BEST for interviewer)
    # - en-US-BrianNeural (Clear, friendly)
    # - en-US-ChristopherNeural (Professional, calm)
    # - en-US-EricNeural (Conversational, natural)
    # - en-US-DavisNeural (Professional, clear)
    # FEMALE:
    # - en-US-JennyNeural (Natural, conversational - BEST female)
    # - en-US-AriaNeural (Warm, friendly)
    # - en-US-MichelleNeural (Professional, clear)
    # - en-US-SaraNeural (Conversational)
    # - en-US-NancyNeural (Professional, articulate)
    # BRITISH:
    # - en-GB-RyanNeural (British male, professional)
    # - en-GB-ThomasNeural (British male, natural)
    # - en-GB-SoniaNeural (British female, clear)

# Voice profiles for different scenarios
voice_profiles:
  professional_interviewer:
    edge_voice: "en-US-AndrewNeural"  # Most natural male voice
    elevenlabs_voice: "ErXwobaYiN019PkySvjV"  # Antoni
    openai_voice: "onyx"
    description: "Professional male interviewer - Alex (warm, conversational)"

  friendly_interviewer:
    edge_voice: "en-US-JennyNeural"  # Most natural female voice
    elevenlabs_voice: "21m00Tcm4TlvDq8ikWAM"  # Rachel
    openai_voice: "nova"
    description: "Friendly female interviewer (natural, warm)"

  technical_interviewer:
    edge_voice: "en-US-ChristopherNeural"  # Professional male
    elevenlabs_voice: "TxGEqnHWrfWFTfGW9XjX"  # Josh
    openai_voice: "echo"
    description: "Technical male interviewer (clear, professional)"

  casual_interviewer:
    edge_voice: "en-US-BrianNeural"  # Friendly conversational
    openai_voice: "fable"
    description: "Casual interviewer (friendly, relaxed)"


# STT (Speech-to-Text) Configuration
# =============================================================================
# RECOMMENDED OPEN-SOURCE STT MODELS (2025-2026)
# =============================================================================
# Best Accuracy:
#   - NVIDIA Canary Qwen 2.5B (#1 on HuggingFace, 5.63% WER)
#   - IBM Granite Speech 3.3 (8B params, 5.85% WER)
#   - Whisper Large V3 (Gold standard, 99+ languages)
#
# Best Speed:
#   - Faster-Whisper (CTranslate2 optimized, 4x faster than Whisper)
#   - Whisper Large V3 Turbo (6x faster, minimal accuracy loss)
#   - NVIDIA Parakeet TDT (RTFx > 2000, fastest)
#
# Best for Real-time:
#   - Faster-Whisper with VAD (voice activity detection)
#   - Deepgram Nova-2 (API, very fast)
#
# Best Offline/Edge:
#   - Vosk (lightweight, CPU-friendly)
#   - Whisper.cpp (C++ optimized)
#   - Moonshine (tiny models for mobile/IoT)
# =============================================================================

stt:
  default: "faster_whisper"  # Options: whisper, faster_whisper, google, browser

  # Faster-Whisper: CTranslate2 optimized Whisper (RECOMMENDED)
  # 4x faster than original Whisper with same accuracy
  faster_whisper:
    # Model sizes: tiny, base, small, medium, large-v2, large-v3
    # Recommended: large-v3 for accuracy, medium for speed/accuracy balance
    model_size: "large-v3"
    device: "auto"  # auto, cuda, cpu
    compute_type: "float16"  # float16, int8, int8_float16
    language: "en"  # null for auto-detect
    beam_size: 5
    vad_filter: true  # Voice Activity Detection for better accuracy
    vad_parameters:
      min_silence_duration_ms: 500
      speech_pad_ms: 400
    # Download models automatically from HuggingFace
    download_root: null  # Uses default cache

  # Original OpenAI Whisper (via API)
  whisper:
    api_key_env: "OPENAI_API_KEY"
    model: "whisper-1"

  # Google Speech-to-Text
  google:
    api_key_env: "GOOGLE_SPEECH_KEY"
    language_code: "en-US"

  # Browser-based (Web Speech API)
  browser:
    # Uses Web Speech API (free, runs in browser)
    language: "en-US"
    continuous: true
    interim_results: true

  # Vosk (lightweight offline)
  vosk:
    model_path: null  # Path to vosk model or will download
    language: "en-us"
    sample_rate: 16000
